{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10907795,"sourceType":"datasetVersion","datasetId":6780077},{"sourceId":11108267,"sourceType":"datasetVersion","datasetId":6925339},{"sourceId":296340,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":253676,"modelId":275112},{"sourceId":296841,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":254071,"modelId":275490},{"sourceId":296843,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":254072,"modelId":275491},{"sourceId":296973,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":254171,"modelId":275593},{"sourceId":296975,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":254172,"modelId":275594},{"sourceId":296976,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":254173,"modelId":275595},{"sourceId":297110,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":254252,"modelId":275667},{"sourceId":297114,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":254255,"modelId":275670},{"sourceId":297117,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":254258,"modelId":275673}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-23T00:48:38.448213Z","iopub.execute_input":"2025-03-23T00:48:38.448554Z","iopub.status.idle":"2025-03-23T00:48:38.471415Z","shell.execute_reply.started":"2025-03-23T00:48:38.448520Z","shell.execute_reply":"2025-03-23T00:48:38.470663Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport joblib\nimport tensorflow as tf\nfrom tensorflow.keras.models import load_model\nfrom sklearn.metrics import accuracy_score, classification_report\nimport xgboost as xgb\n\n# LOAD SAVED LIGHTGBM PIPELINE\nlgb_preprocessing_pipeline = joblib.load(\"/kaggle/input/lgb_preprocessing_pipeline/scikitlearn/default/1/lgb_preprocessing_pipeline.joblib\")\nlgb_label_encoder = joblib.load(\"/kaggle/input/lgb_label_encoder/scikitlearn/default/1/lgb_label_encoder.joblib\")\nfinal_model_lightgbm = joblib.load(\"/kaggle/input/final_model_lightgbm/keras/default/1/final_model_lightgbm.joblib\")\n\n# LOAD NEURAL NETWORK MODEL\nfinal_model_nn = load_model(\"/kaggle/input/final_model_cosmicclassifier/keras/default/1/final_model_cosmicclassifier.h5\")\nnn_preprocessing_pipeline = joblib.load(\"/kaggle/input/processing_pipeline/scikitlearn/default/1/preprocessing_pipeline.pkl\")\nnn_label_encoder = joblib.load(\"/kaggle/input/label_encoder/scikitlearn/default/1/label_encoder.pkl\")\n# We'll treat nn_label_encoder as the master encoder for final decoding.\n\n# LOAD XGBOOST PIPELINE\nxgb_preprocessing_pipeline = joblib.load(\"/kaggle/input/xgb_preprocessing_pipeline_real/scikitlearn/default/1/xgb_preprocessing_pipeline_real.joblib\")\nxgb_label_encoder = joblib.load(\"/kaggle/input/xgb_label_encoder_real/scikitlearn/default/1/xgb_label_encoder_real.joblib\")\nfinal_model_xgb = joblib.load(\"/kaggle/input/final_model_xgboost_real/scikitlearn/default/1/final_model_xgboost_real.joblib\")\n\n# REORDER PROBABILITY COLUMNS \ndef reorder_probability_columns(model_prob, model_classes, master_classes):\n    def is_nan(x):\n        return isinstance(x, float) and np.isnan(x)\n    \n    # Build sets excluding NaN for comparison.\n    model_set = {x for x in model_classes if not is_nan(x)}\n    master_set = {x for x in master_classes if not is_nan(x)}\n    \n    model_has_nan = any(is_nan(x) for x in model_classes)\n    master_has_nan = any(is_nan(x) for x in master_classes)\n    \n    if model_set != master_set or model_has_nan != master_has_nan:\n        raise ValueError(\n            f\"Cannot reorder columns because class sets differ.\\n\"\n            f\"Model classes: {model_classes}\\n\"\n            f\"Master classes: {master_classes}\"\n        )\n    \n    reorder_indices = []\n    for cls in master_classes:\n        found_index = None\n        for idx, m_cls in enumerate(model_classes):\n            if is_nan(cls) and is_nan(m_cls):\n                found_index = idx\n                break\n            elif cls == m_cls:\n                found_index = idx\n                break\n        if found_index is None:\n            raise ValueError(f\"Class {cls} not found in model classes {model_classes}.\")\n        reorder_indices.append(found_index)\n    \n    return model_prob[:, reorder_indices]\n\n# READ file AND PREPARE FEATURES\nnew_data_path = \"/kaggle/input/testing-data-cogni1/cosmicclassifierTest.csv\"  \ndf_new = pd.read_csv(new_data_path)\n\nfeatures = [\n    \"Atmospheric Density\",\n    \"Surface Temperature\",\n    \"Gravity\",\n    \"Water Content\",\n    \"Mineral Abundance\",\n    \"Orbital Period\",\n    \"Proximity to Star\",\n    \"Magnetic Field Strength\",\n    \"Radiation Levels\",\n    \"Atmospheric Composition Index\"\n]\n\ndef category_to_float(val):\n    if isinstance(val, str) and val.startswith(\"Category_\"):\n        return float(val.replace(\"Category_\", \"\"))\n    return val\n\nfor col in [\"Magnetic Field Strength\", \"Radiation Levels\"]:\n    if col in df_new.columns:\n        df_new[col] = df_new[col].apply(category_to_float)\n\npossible_target_cols = {\"Output\", \"Prediction\"}\nfound_target = list(possible_target_cols.intersection(df_new.columns))\n\nif found_target:\n    target_col = found_target[0]\n    y_true = df_new[target_col].values\n    # Using the master (NN) label encoder \n    y_true_encoded = nn_label_encoder.transform(y_true)\nelse:\n    target_col = None\n    y_true = None\n    y_true_encoded = None\n\n# PREPARE THE FEATURES FOR EACH MODEL\nX_new = df_new[features].copy()\n\nX_lgb = lgb_preprocessing_pipeline.transform(X_new)\nX_nn = nn_preprocessing_pipeline.transform(X_new)\nX_xgb = xgb_preprocessing_pipeline.transform(X_new)\n\n# GET PREDICTED PROBABILITIES FROM EACH MODEL\n# LightGBM predictions and reordering to master class order\nprobs_lgb_raw = final_model_lightgbm.predict_proba(X_lgb)\nprobs_lgb = reorder_probability_columns(\n    model_prob=probs_lgb_raw,\n    model_classes=lgb_label_encoder.classes_,\n    master_classes=nn_label_encoder.classes_\n)\n\n# Neural Network predictions (already using master order)\nprobs_nn = final_model_nn.predict(X_nn)\n\n# XGBoost predictions and reordering\nprobs_xgb_raw = final_model_xgb.predict_proba(X_xgb)\nprobs_xgb = reorder_probability_columns(\n    model_prob=probs_xgb_raw,\n    model_classes=xgb_label_encoder.classes_,\n    master_classes=nn_label_encoder.classes_\n)\n\n# COMBINE PROBABILITIES VIA SOFT VOTING AND OBTAIN FINAL PREDICTIONS\nensemble_probs = (probs_lgb + probs_nn + probs_xgb) / 3.0\nensemble_preds_encoded = np.argmax(ensemble_probs, axis=1)\nensemble_preds_labels = nn_label_encoder.inverse_transform(ensemble_preds_encoded)\n\n# EVALUATE PERFORMANCE IF TRUE LABELS ARE AVAILABLE & CREATE SUBMISSION FILE\nif y_true is not None:\n    acc = accuracy_score(y_true_encoded, ensemble_preds_encoded)\n    print(f\"Ensemble Accuracy: {acc:.4f}\")\n    print(\"\\nClassification Report:\")\n    print(classification_report(y_true_encoded, ensemble_preds_encoded))\n\nid_col = \"Planet_ID\"\nif id_col not in df_new.columns:\n    df_new[id_col] = np.arange(len(df_new))\n\nsubmission = pd.DataFrame({\n    id_col: df_new[id_col],\n    \"Final_Ensemble_Prediction\": ensemble_preds_labels\n})\n\nsubmission.to_csv(\"ensemble_submission.csv\", index=False)\nprint(\"\\nEnsemble submission saved as 'ensemble_submission.csv'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T01:31:56.702501Z","iopub.execute_input":"2025-03-23T01:31:56.702814Z","iopub.status.idle":"2025-03-23T01:32:02.466052Z","shell.execute_reply.started":"2025-03-23T01:31:56.702788Z","shell.execute_reply":"2025-03-23T01:32:02.465091Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}